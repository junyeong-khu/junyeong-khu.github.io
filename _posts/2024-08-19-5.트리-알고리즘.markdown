---
layout: post
title: "í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ : 5. íŠ¸ë¦¬ ì•Œê³ ë¦¬ì¦˜"
date: 2024-08-20 03:01:45 +0900
categories: í˜¼ì_ê³µë¶€í•˜ëŠ”_ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹
---
## <span style= 'background-color: #f1f8ff'>5-1: ê²°ì • íŠ¸ë¦¬
**â˜† ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ ì™€ì¸ ë¶„ë¥˜í•˜ê¸°: classê°€ 0ì´ë©´ ë ˆë“œ ì™€ì¸, 1ì´ë©´ í™”ì´íŠ¸ ì™€ì¸.**

```python
#ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì´ìš©í•œ ì™€ì¸ ë¶„ë¥˜ ê³¼ì • 1

import pandas as pd
wine = pd.read_csv('https://bit.ly/wine-date')

wine.info() #ê° ì—´ì˜ ë°ì´í„° íƒ€ì…ê³¼ ëˆ„ë½ëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
```
â¡ï¸
![image](https://github.com/user-attachments/assets/85fe66c8-055c-48fe-8221-2d110e3321f7)

âŠ• í•´ì„: 6497 entriesë¥¼ í†µí•´ 6,497ê°œì˜ ìƒ˜í”Œì´ ìˆìŒì„ í™•ì¸. 4ê°œì˜ ì—´ì´ ëª¨ë‘ floatì¸ ê²ƒì„ ë³´ì•„ ëª¨ë‘ ì‹¤ìˆ«ê°’. Non-Null Countê°€ ëª¨ë‘ 6497ì´ë¯€ë¡œ ëˆ„ë½ëœ ê°’ì€ ì—†ìŒ.

ğŸ“Œ ëˆ„ë½ëœ ê°’ì´ ìˆëŠ” ê²½ìš°: í•´ë‹¹ ë°ì´í„°ë¥¼ ë²„ë¦¬ê±°ë‚˜ í‰ê· ê°’ìœ¼ë¡œ ì±„ìš´ í›„ ì‚¬ìš©.

```python
#ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì´ìš©í•œ ì™€ì¸ ë¶„ë¥˜ ê³¼ì • 2

wine.describe() #ì—´ì— ëŒ€í•œ ê°„ëµí•œ í†µê³„ë¥¼ ì¶œë ¥
```
![image](https://github.com/user-attachments/assets/10eb1b08-fd59-4741-9b38-f0122d0a53c7)

```python
#ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì´ìš©í•œ ì™€ì¸ ë¶„ë¥˜ ê³¼ì • 3

data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()

from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
ss.fit(train_input)
train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(train_scaled, train_target)
print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))
```
â¡ï¸ 0.7808350971714451
â¡ï¸ 0.7776923076923077

**â˜† ê²°ì • íŠ¸ë¦¬: ì•Œê³ ë¦¬ì¦˜ì„ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ì—¬ ì˜ì‚¬ë¥¼ ê²°ì •í•˜ê±°ë‚˜ ì‹œê°„ ë³µì¡ë„ë¥¼ ì¦ëª…í•˜ëŠ” ë° ì‚¬ìš©í•˜ëŠ” íŠ¸ë¦¬.**

```python
#ê²°ì • íŠ¸ë¦¬ ëª¨ë¸ í›ˆë ¨

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(train_scaled, train_target)
print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
```
â¡ï¸ 0.996921300750433
â¡ï¸ 0.8592307692307692 (ê³¼ëŒ€ì í•©)

```python
#ê²°ì • íŠ¸ë¦¬ ê·¸ë¦¼ ì¶œë ¥

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
plt.figure(figsize=(10,7))
plot_tree(dt)
plt.show()
```
â¡ï¸
![image](https://github.com/user-attachments/assets/b2a2dc90-8b7c-437e-a440-9ad37d8bb705)

ğŸ“Œ ë…¸ë“œ: ê²°ì • íŠ¸ë¦¬ë¥¼ êµ¬ì„±í•˜ëŠ” í•µì‹¬ ìš”ì†Œë¡œ í›ˆë ¨ ë°ì´í„°ì˜ íŠ¹ì„±ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ë¥¼ í‘œí˜„.

```python
#ê²°ì • íŠ¸ë¦¬ ê·¸ë¦¼ ê°„ê²°íˆ ì¶œë ¥

plt.figure(figsize=(10,7))
plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol', 'sugar', 'pH']) 
#max_depthë¥¼ 1ë¡œ ì„¤ì •í•˜ë©´ ë£¨íŠ¸ ë…¸ë“œë¥¼ ì œì™¸í•˜ê³  í•˜ë‚˜ì˜ ë…¸ë“œë¥¼ ë” í™•ì¥í•˜ì—¬ ê·¸ë¦¼
#filledë¥¼ Trueë¡œ ì§€ì •í•˜ë©´ í´ë˜ìŠ¤ë§ˆë‹¤ ìƒ‰ê¹”ì„ ë¶€ì—¬í•˜ê³ , ì–´ë–¤ í´ë˜ìŠ¤ì˜ ë¹„ìœ¨ì´ ë†’ì•„ì§€ë©´ ì ì  ì§„í•œ ìƒ‰ìœ¼ë¡œ í‘œì‹œí•¨
plt.show()
```
â¡ï¸
![image](https://github.com/user-attachments/assets/fa6d30d1-02b6-4881-82da-e525789882da)

(value ë¦¬ìŠ¤íŠ¸ì˜ ì™¼ìª½ì´ ìŒì„± í´ë˜ìŠ¤, ì˜¤ë¥¸ìª½ì´ ì–‘ì„± í´ë˜ìŠ¤)

ğŸ“Œ ê²°ì • íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ ë°©ë²•: ë¦¬í”„ ë…¸ë“œì—ì„œ ê°€ì¥ ë§ì€ í´ë˜ìŠ¤ê°€ ì˜ˆì¸¡ í´ë˜ìŠ¤ê°€ ë¨.

**â˜† ì§€ë‹ˆ ë¶ˆìˆœë„: criterion ë§¤ê°œë³€ìˆ˜ë¡œ ë…¸ë“œì—ì„œ ë°ì´í„°ë¥¼ ë¶„í• í•  ê¸°ì¤€ì„ ì •í•˜ëŠ”ë°, DecisionTreeClassifier í´ë˜ìŠ¤ì˜ criterion ë§¤ê°œë³€ìˆ˜ì˜ ê¸°ë³¸ê°’ì´ 'gini'ì„.**

![image](https://github.com/user-attachments/assets/a3c448c5-3158-4a1f-a5b2-c7d8c448861f)
â¬†ï¸ ì§€ë‹ˆ ë¶ˆìˆœë„ì˜ ê³„ì‚°

ğŸ“Œ ê²°ì • íŠ¸ë¦¬ì˜ íŠ¸ë¦¬ ì„±ì¥: ë¶€ëª¨ ë…¸ë“œì™€ ìì‹ ë…¸ë“œì˜ ë¶ˆìˆœë„ ì°¨ì´ê°€ ê°€ëŠ¥í•œ í¬ë„ë¡ íŠ¸ë¦¬ë¥¼ ì„±ì¥ì‹œí‚´. ì´ë•Œ ë¶€ëª¨ì™€ ìì‹ ë…¸ë“œ ì‚¬ì´ì˜ ë¶ˆìˆœë„ ì°¨ì´ë¥¼ **ì •ë³´ ì´ë“**ì´ë¼ê³  ë¶€ë¦„.

![image](https://github.com/user-attachments/assets/7ede413d-fe51-4c83-8cef-e31f55592f5a)
â¬†ï¸ ì™¼ìª½ ë…¸ë“œë¡œ 2,922ê°œì˜ ìƒ˜í”Œì´ ì´ë™í•˜ê³  ì˜¤ë¥¸ìª½ ë…¸ë“œë¡œ 2,275ê°œì˜ ìƒ˜í”Œì´ ì´ë™í–ˆì„ ê²½ìš° ë¶ˆìˆœë„ì˜ ì°¨ì´ ê³„ì‚°

âŠ• ì—”íŠ¸ë¡œí”¼ ë¶ˆìˆœë„: DecisionTreeClassifier í´ë˜ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” ë˜ë‹¤ë¥¸ criterion ë§¤ê°œë³€ìˆ˜ì˜ ì¢…ë¥˜. ì œê³±ì´ ì•„ë‹Œ ë°‘ì´ 2ì¸ ë¡œê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³±í•¨.

**â˜† ê°€ì§€ì¹˜ê¸°: ê³¼ëŒ€ì í•©ì„ ë§‰ê¸° ìœ„í•œ ë°©ë²•. íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ë¥¼ ì§€ì •í•˜ë©´ ê°€ì¥ ê°„ë‹¨íˆ ê°€ì§€ì¹˜ê¸°ë¥¼ í•  ìˆ˜ ìˆìŒ.**

```python
#ê°€ì§€ì¹˜ê¸°

dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_scaled, train_target)
print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
```
â¡ï¸ 0.8454877814123533
â¡ï¸ 0.8415384615384616 (ê³¼ëŒ€ì í•© ì™„í™”)

```python
#ê°€ì§€ì¹˜ê¸°í•œ ëª¨ë¸ íŠ¸ë¦¬ ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚´ê¸°

plt.flgure(figsize=(20,15))
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```
â¡ï¸
![image](https://github.com/user-attachments/assets/4abec3d7-964b-4806-bcd5-f6306f145288)

âŠ• ê²°ì • íŠ¸ë¦¬ì˜ ì¥ì : ê²°ì • íŠ¸ë¦¬ ì•Œê³ ë¦¬ì¦˜ì€ ë¶ˆìˆœë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒ˜í”Œì„ ë‚˜ëˆ„ê³ , ë¶ˆìˆœë„ëŠ” í´ë˜ìŠ¤ë³„ ë¹„ìœ¨ì„ ê°€ì§€ê³  ê³„ì‚°í•¨. ì¦‰ íŠ¹ì„±ê°’ì˜ ìŠ¤ì¼€ì¼ì€ ê³„ì‚°ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šìœ¼ë¯€ë¡œ í‘œì¤€í™” ì „ì²˜ë¦¬ê°€ í•„ìš” ì—†ìŒ.

```python
#í‘œì¤€í™” ì „ì²˜ë¦¬ í•˜ì§€ ì•Šì€ ëª¨ë¸ì˜ íŠ¸ë¦¬ ì‘ì„±

dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_input, train_target)

plt.figure(figsize=(20,15))
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```
â¡ï¸
![image](https://github.com/user-attachments/assets/ff47dfb8-f8d2-4e23-8d71-55f1fe5962c8)

âŠ• ê²°ì • íŠ¸ë¦¬ì˜ íŠ¹ì§•: ì–´ë–¤ íŠ¹ì„±ì´ ê°€ì¥ ìœ ìš©í•œì§€ ë‚˜íƒ€ë‚´ëŠ” íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•´ì¤Œ.

```python
#íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥

print(dt.feature_importances_)
```
â¡ï¸ [0.12345626 0.86862934 0.0079144]

## <span style= 'background-color: #f1f8ff'>5-2: êµì°¨ ê²€ì¦ê³¼ ê·¸ë¦¬ë“œ ì„œì¹˜
**â˜† ê²€ì¦ ì„¸íŠ¸: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ëª¨ë¸ì˜ ê³¼ëŒ€â€¢ê³¼ì†Œì í•© ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•´ í›ˆë ¨ ì„¸íŠ¸ë¥¼ ë˜ë‹¤ì‹œ ë‚˜ëˆˆ ë°ì´í„° ì„¸íŠ¸.**

```python
#ê²€ì¦ ì„¸íŠ¸ ìƒì„±

import pandas as pd
wine = pd.read_csv('https://bit.ly/wine-data')

data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()

from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)

sub_input, val_input, sub_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)

#ê²€ì¦ ì„¸íŠ¸ë¥¼ í†µí•œ í‰ê°€

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(sub_input, sub_target)
print(dt.score(sub_input, sub_target))
print(dt.score(val_input, val_target))
```
â¡ï¸ 0.9971133028626413
â¡ï¸ 0.864423076923077 (ê³¼ëŒ€ì í•©)

**â˜† êµì°¨ ê²€ì¦: ê²€ì¦ ì„¸íŠ¸ë¥¼ ë–¼ì–´ ë‚´ì–´ í‰ê°€í•˜ëŠ” ê³¼ì •ì„ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ. ì´í›„ ì ìˆ˜ë“¤ì„ í‰ê· í•˜ì—¬ ìµœì¢… ê²€ì¦ ì ìˆ˜ë¥¼ ì–»ìŒ**

![image](https://github.com/user-attachments/assets/cee90f11-f165-4ced-8797-75eadc67b554)
â¬†ï¸ 3-í´ë“œ êµì°¨ ê²€ì¦ì˜ ì›ë¦¬ 

```python
#êµì°¨ ê²€ì¦ ì‹¤ìŠµ

from sklearn.model_selection import cross_validate
scores = cross_validate(dt, train_input, train_target)
print(scores)
```
â¡ï¸ 
![image](https://github.com/user-attachments/assets/3bb36cfd-4d5f-4ad5-9fc9-4995c8a281a2)

(fit_time, score_timeì€ ê°ê° ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ì‹œê°„ê³¼ ê²€ì¦í•˜ëŠ” ì‹œê°„ì„ ì˜ë¯¸. cross_validate() í•¨ìˆ˜ëŠ” 5-í´ë“œ êµì°¨ ê²€ì¦ì„ ìˆ˜í–‰í•˜ê¸°ì— ê° í‚¤ë§ˆë‹¤ 5ê°œì˜ ìˆ«ìê°€ ë‹´ê²¨ ìˆìŒ.)

ğŸ“Œ êµì°¨ ê²€ì¦ ìµœì¢… ì ìˆ˜: test_score í‚¤ì— ë‹´ê¸´ 5ê°œì˜ ì ìˆ˜ë¥¼ í‰ê· í•˜ì—¬ ì–»ì„ ìˆ˜ ìˆìŒ.

```python
#êµì°¨ ê²€ì¦ ìµœì¢… ì ìˆ˜ ì¶œë ¥

import numpy as np
print(np.mean(scores['test_score']))
```
â¡ï¸ 0.855300214703487

ğŸš¨ ì£¼ì˜: cross_validate()ëŠ” í›ˆë ¨ ì„¸íŠ¸ë¥¼ ì„ì–´ í´ë“œë¥¼ ë‚˜ëˆ„ì§€ ì•ŠìŒ. êµì°¨ ê²€ì¦ì„ í•  ë•Œ í›ˆë ¨ ì„¸íŠ¸ë¥¼ ì„ìœ¼ë ¤ë©´ ë¶„í• ê¸°ë¥¼ ì§€ì •í•´ì•¼í•¨. cross_validate()ëŠ” íšŒê·€ ëª¨ë¸ì¼ ê²½ìš° KFold ë¶„í• ê¸°ë¥¼ ì‚¬ìš©í•˜ê³  ë¶„ë¥˜ ëª¨ë¸ì¼ ê²½ìš° StratifiedKFold ë¶„í• ê¸°ë¥¼ ì‚¬ìš©.

```python
#ë¶„í• ê¸° ì§€ì •

from sklearn.model_selection import StratifiedKFold
scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))
```
â¡ï¸ 0.8574181117533719

âŠ• 10-í´ë“œ êµì°¨ ê²€ì¦ ìˆ˜í–‰ ë°©ë²•

```python
splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_validate(dt, train_input, train_target, cv=splitter)
```

**â˜† í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹: ëª¨ë¸ì´ í•™ìŠµí•  ìˆ˜ ì—†ì–´ì„œ ì‚¬ìš©ìê°€ ì§€ì •í•´ì•¼ë§Œ í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¼ê³  í•¨. ì´ëŸ¬í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì€ ì„œë¡œ ì˜í–¥ì„ ë¯¸ì¹˜ê¸°ì— ë™ì‹œì— ë°”ê¿”ê°€ë©° ìµœì ì˜ ê°’ì„ ì°¾ì•„ë‚´ì•¼ í•¨.**

```python
#ê·¸ë¦¬ë“œ ì„œì¹˜ë¥¼ ì´ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
#min_impurity_decreaseëŠ” ë…¸ë“œë¥¼ ë¶„í• í•˜ê¸° ìœ„í•œ ë¶ˆìˆœë„ ê°ì†Œ ìµœì†ŒëŸ‰ì„ ì§€ì •

from sklearn.model_selection import GridSearchCV
params = {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}

gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params,n_jobs=-1) #n_jobsë¥¼ ì§€ì •í•´ ë³‘ë ¬ ì‹¤í–‰ì— ì‚¬ìš©í•  CPU ì½”ì–´ ìˆ˜ë¥¼ ì§€ì •. -1ë¡œ ì§€ì •í•  ê²½ìš° ì‹œìŠ¤í…œì— ìˆëŠ” ëª¨ë“  ì½”ì–´ë¥¼ ì‚¬ìš©í•¨

gs.fit(train_input, train_target)

dt = gs.best_estimator_ #ìµœì ì˜ ëª¨ë¸ì´ ì €ì¥ëœ ì†ì„±
print(dt.score(train_input, train_target))
print(gs.best_params_)
print(gs.cv_results_['mean_test_score']) #í‰ê·  ì ìˆ˜ ì¶œë ¥
```
â¡ï¸ 0.9615162593804117
â¡ï¸ {'min_impurity_decrease': 0.0001}
â¡ï¸ [0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]

ğŸ“Œ ê·¸ë¦¬ë“œ ì„œì¹˜ì˜ ì¥ì : í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ê³¼ êµì°¨ ê²€ì¦ì„ í•œ ë²ˆì— ìˆ˜í–‰í•˜ê³ , í›ˆë ¨ì´ ëë‚˜ë©´ ê²€ì¦ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ ì¡°í•©ìœ¼ë¡œ ì „ì²´ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ìë™ìœ¼ë¡œ ë‹¤ì‹œ ëª¨ë¸ì„ í›ˆë ¨í•¨.

```python
#argmax() í•¨ìˆ˜ë¥¼ í™œìš©í•œ ìµœì  ë§¤ê°œë³€ìˆ˜ ì¶œë ¥

best_index = np.argmax(gs.cv_results_['mean_test_score'])
print(gs.cv_results_['params'][best_index])
```
â¡ï¸ {'min_impurity_decrease': 0.0001}

```python
#ë³µì¡í•œ ë§¤ê°œë³€ìˆ˜ ì¡°í•© íƒìƒ‰
#min_samples_splitì€ ë…¸ë“œë¥¼ ë‚˜ëˆ„ê¸° ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜

params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001), #0.0001ì—ì„œ 0.001ì´ ë  ë•Œê¹Œì§€ 0.0001ì”© ë”í•œ ë°°ì—´. 0.001ì€ ë°°ì—´ì— í¬í•¨ë˜ì§€ ì•ŠìŒ
'max_depth': range(5, 20, 1), #5ì—ì„œ 20ì´ ë  ë•Œê¹Œì§€ 1ì”© ë”í•œ ë°°ì—´. 20ì€ ë°°ì—´ì— í¬í•¨ë˜ì§€ ì•ŠìŒ
'min_samples_split': range(2, 100, 10) #2ì—ì„œ 100ì´ ë  ë•Œê¹Œì§€ 10ì”© ë”í•œ ë°°ì—´. 100ì€ í¬í•¨ë˜ì§€ ì•ŠìŒ
}

gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)

print(gs.best_params_)
```
â¡ï¸ {'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}

```python
#ìµœìƒì˜ êµì°¨ ê²€ì¦ ì ìˆ˜ ì¶œë ¥

print(np.max(gs.cv_results_['mean_test_score']))
```
â¡ï¸ 0.8683865773302731

ğŸ“Œ arangeì™€ rangeì˜ ì°¨ì´: rangeëŠ” ì •ìˆ˜ë§Œ ì‚¬ìš© ê°€ëŠ¥.

**â˜† ëœë¤ ì„œì¹˜: ì„ì˜ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„ ì •í•˜ëŠ” ê³¼ì •ì„ í†µí•´ ìµœì ì˜ í•´ë¥¼ ì°¾ì•„ê°€ëŠ” ê¸°ë²•. ëœë¤ ì„œì¹˜ì—ëŠ” ë§¤ê°œë³€ìˆ˜ ê°’ì˜ ëª©ë¡ì„ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë§¤ê°œë³€ìˆ˜ë¥¼ ìƒ˜í”Œë§í•  ìˆ˜ ìˆëŠ” í™•ë¥  ë¶„í¬ ê°ì²´ë¥¼ ì „ë‹¬í•¨.**

```python
#ëœë¤ ì„œì¹˜ ì‹¤ìŠµ 1

from scipy.stats import uniform, randint #ë‘ í´ë˜ìŠ¤ ëª¨ë‘ ì£¼ì–´ì§„ ë²”ìœ„ì—ì„œ ê³ ë¥´ê²Œ ê°’ì„ ì„ ì •í•¨. uniformì€ ì‹¤ìˆ«ê°’ì„ ë½‘ê³  randintëŠ” ì •ìˆ«ê°’ì„ ë½‘ìŒ

rgen = randint(0, 10)
rgen.rvs(10)
```
â¡ï¸ array([6, 4, 2, 2, 7, 7, 0, 0, 5, 4])

```python
#ëœë¤ ì„œì¹˜ ì‹¤ìŠµ 2

np.unique(rgen.rvs(1000), return_counts=True)
```
â¡ï¸ 
(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
array([ 98, 94, 99, 93, 93, 92, 111, 118, 105, 97]))

âŠ• uniform í´ë˜ìŠ¤ì˜ ì‚¬ìš©ë²•ë„ ë™ì¼.

```python
#ëœë¤ ì„œì¹˜ ì‹¤ìŠµ 3
#min_samples_leafëŠ” ë¦¬í”„ ë…¸ë“œê°€ ë˜ê¸° ìœ„í•œ ìµœì†Œ ìƒ˜í”Œì˜ ê°œìˆ˜. ì´ ê°’ë³´ë‹¤ ì‘ì„ ê²½ìš° ë…¸ë“œë¥¼ ë¶„í• í•˜ì§€ ì•ŠìŒ.

params = {'min_impurity_decrease': uniform(0.0001, 0.001),
'max_depth': randint(20, 50),
'min_samples_split': randint(2,25),
'min_samples_leaf': randint(1, 25),
}

from sklearn.model_selection import RandomizedSearchCV
gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, n_iter=100, n_jobs=-1, random_state=42) #n_iterë¡œ ìƒ˜í”Œë§ íšŸìˆ˜ë¥¼ ì§€ì •
gs.fit(train_input, train_target)

print(gs.best_params_)
```
â¡ï¸
{'max_depth': 39, 'min_impurity_decrease': 0.00034102546602601173, 'min_samples_leaf': 7, 'min_samples_split': 13}

```python
#ìµœìƒì˜ êµì°¨ ê²€ì¦ ì ìˆ˜ ì¶œë ¥

print(np.max(gs.cv_results_['mean_test_score']))
```
â¡ï¸ 0.8695428296438884

## <span style= 'background-color: #f1f8ff'>5-3: íŠ¸ë¦¬ì˜ ì•™ìƒë¸”
**â˜† ì •í˜• ë°ì´í„°ì™€ ë¹„ì •í˜• ë°ì´í„°: ì–´ë–¤ êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì§„ ë°ì´í„°ë¥¼ ì •í˜• ë°ì´í„°ë¼ê³  ë¶€ë¥´ê³  ì´ì™€ ë°˜ëŒ€ë˜ëŠ” ë°ì´í„°ë¥¼ ë¹„ì •í˜• ë°ì´í„°ë¼ê³  ë¶€ë¦„. ì •í˜• ë°ì´í„°ëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ì—‘ì…€ë¡œ í‘œí˜„í•˜ê¸° ì‰½ì§€ë§Œ ë¹„ì •í˜• ë°ì´í„°ëŠ” ì•„ë‹˜.**

âŠ• ì•™ìƒë¸” í•™ìŠµ: ì •í˜• ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë° ê°€ì¥ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë‚´ëŠ” ì•Œê³ ë¦¬ì¦˜. ì´ ì•Œê³ ë¦¬ì¦˜ì€ ëŒ€ë¶€ë¶„ ê²°ì • íŠ¸ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì ¸ ìˆìŒ.

âŠ• ì‹ ê²½ë§ ì•Œê³ ë¦¬ì¦˜: ë¹„ì •í˜• ë°ì´í„°ì— ì‚¬ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜

**â˜† ëœë¤ í¬ë ˆìŠ¤íŠ¸: ì•™ìƒë¸” í•™ìŠµì˜ ëŒ€í‘œ ì£¼ì ì¤‘ í•˜ë‚˜ë¡œ ì•ˆì •ì ì¸ ì„±ëŠ¥ ë•ë¶„ì— ë„ë¦¬ ì‚¬ìš©ë¨. ê²°ì • íŠ¸ë¦¬ë¥¼ ëœë¤í•˜ê²Œ ë§Œë“¤ì–´ ê²°ì • íŠ¸ë¦¬ì˜ ìˆ²ì„ ë§Œë“¤ê³  ê° ê²°ì • íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ì„ ì‚¬ìš©í•´ ìµœì¢… ì˜ˆì¸¡ì„ ë§Œë“¦. ê¸°ë³¸ì ìœ¼ë¡œ 100ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¥¼ í›ˆë ¨í•¨.**

**â˜† ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ íŠ¸ë¦¬ í›ˆë ¨ ë°©ì‹**
1. ì…ë ¥í•œ í›ˆë ¨ ë°ì´í„°ì—ì„œ ëœë¤í•˜ê²Œ ìƒ˜í”Œì„ ì¶”ì¶œí•˜ì—¬ í›ˆë ¨ ë°ì´í„°ë¥¼ ë§Œë“¦. ì´ë•Œ í•œ ìƒ˜í”Œì´ ì¤‘ë³µë˜ì–´ ì¶”ì¶œë  ìˆ˜ë„ ìˆìŒ. ì´ë ‡ê²Œ ë§Œë“¤ì–´ì§„ ìƒ˜í”Œì„ **ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œ**ì´ë¼ê³  ë¶€ë¦„.
2. ê° ë…¸ë“œë¥¼ ë¶„í• í•  ë•Œ ì „ì²´ íŠ¹ì„± ì¤‘ì—ì„œ ì¼ë¶€ íŠ¹ì„±ì„ ë¬´ì‘ìœ„ë¡œ ê³ ë¥¸ ë‹¤ìŒ ì´ ì¤‘ì—ì„œ ìµœì„ ì˜ ë¶„í• ì„ ì°¾ìŒ.

**â˜† ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ìµœì¢… ì˜ˆì¸¡: ë¶„ë¥˜ì¼ ê²½ìš° ê° íŠ¸ë¦¬ì˜ í´ë˜ìŠ¤ë³„ í™•ë¥ ì„ í‰ê· í•˜ì—¬ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡ìœ¼ë¡œ ì‚¼ìŒ. íšŒê·€ì¼ ë•ŒëŠ” ë‹¨ìˆœíˆ ê° íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ì„ í‰ê· í•¨.**

**â˜† ëœë¤ í¬ë ˆìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ì™€ì¸ ë¶„ë¥˜ ë¬¸ì œ**

```python
#ëœë¤ í¬ë ˆìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ì™€ì¸ ë¶„ë¥˜ ë¬¸ì œ

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
wine = pd.read_csv('https://bit.ly/wine-date')
data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()
train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)

from sklearn.model_selection import cross_validate
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_jobs=-1, random_state=42)
scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1) #return_train_scoreë¥¼ Trueë¡œ ì§€ì •í•˜ë©´ í›ˆë ¨ ì„¸íŠ¸ì— ëŒ€í•œ ì ìˆ˜ë„ ê°™ì´ ë°˜í™˜í•¨
print(np.mean(scores['train_score']), np.mean(scores['test_score']))
```
â¡ï¸ 0.9973541965122431 0.8905151032797809 (ê³¼ëŒ€ì í•©)

ğŸ“Œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ íŠ¹ì§•: DecisionTreeClassifierê°€ ì œê³µí•˜ëŠ” ì¤‘ìš”í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ëª¨ë‘ ì œê³µí•¨. ë˜í•œ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•˜ëŠ”ë°, ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ëŠ” ê° ê²°ì • íŠ¸ë¦¬ì˜ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì·¨í•©í•œ ê²ƒì„.

**â˜† OOB ìƒ˜í”Œì„ ì´ìš©í•œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ í‰ê°€: ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œì— í¬í•¨ë˜ì§€ ì•Šê³  ë‚¨ëŠ” ìƒ˜í”Œì„ OOB ìƒ˜í”Œì´ë¼ê³  í•˜ëŠ”ë° ì´ ìƒ˜í”Œì„ ì´ìš©í•˜ì—¬ ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œë¡œ í›ˆë ¨í•œ ê²°ì • íŠ¸ë¦¬ë¥¼ í‰ê°€í•  ìˆ˜ ìˆìŒ**

```python
#OOB ìƒ˜í”Œì„ ì´ìš©í•œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ í‰ê°€

rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)
rf.fit(train_input, train_target)
print(rf.oob_score_)
```
â¡ï¸ 0.8934000384837406

**â˜† ì—‘ìŠ¤íŠ¸ë¼ íŠ¸ë¦¬: ëœë¤ í¬ë ˆìŠ¤íŠ¸ì™€ ë§¤ìš° ë¹„ìŠ·í•˜ê²Œ ë™ì‘í•˜ì§€ë§Œ, ì—‘ìŠ¤íŠ¸ë¼ íŠ¸ë¦¬ëŠ” ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ë…¸ë“œë¥¼ ë¶„í• í•  ë•Œ ê°€ì¥ ì¢‹ì€ ë¶„í• ì„ ì°¾ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë¬´ì‘ìœ„ë¡œ ë¶„í• í•¨.**

```python
#ì—‘ìŠ¤íŠ¸ë¼ íŠ¸ë¦¬ ì‹¤ìŠµ

from sklearn.ensemble import ExtranTreesClassifier
et = ExtraTreesClassifier(n_jobs=-1, random_state=42)
scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)
print(np.mean(scores['train_score']), np.mean(scores['test_score']))
```
â¡ï¸ 0.9974503966084433 0.8887848893166506

ğŸ“Œ ì—‘ìŠ¤íŠ¸ë¼ íŠ¸ë¦¬ì˜ íŠ¹ì§•: ë¬´ì‘ìœ„ì„±ì´ ëœë¤ í¬ë ˆìŠ¤íŠ¸ì— ë¹„í•´ ì¢€ ë” í¬ê¸° ë•Œë¬¸ì— ë” ë§ì€ ê²°ì • íŠ¸ë¦¬ë¥¼ í›ˆë ¨í•´ì•¼ í•¨. í•˜ì§€ë§Œ ë…¸ë“œë¥¼ ëœë¤í•˜ê²Œ ë¶„í• í•˜ê¸° ë•Œë¬¸ì— ê³„ì‚° ì†ë„ê°€ ë¹ ë¦„.

**â˜† ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…: ê¹Šì´ê°€ ì–•ì€ ê²°ì • íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ì „ íŠ¸ë¦¬ì˜ ì˜¤ì°¨ë¥¼ ë³´ì™„í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì•™ìƒë¸” í•˜ëŠ” ë°©ë²•. ê²½ì‚¬ í•˜ê°•ë²•ì„ ì‚¬ìš©í•˜ì—¬ íŠ¸ë¦¬ë¥¼ ì•™ìƒë¸”ì— ì¶”ê°€í•¨.**

```python
#ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ì‹¤ìŠµ

from sklearn.ensemble import GradientBoostingClassifier
gb = GradientBoostingClassifier(random_state=42) #n_estimators ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ê²°ì • íŠ¸ë¦¬ ê°œìˆ˜ ì¡°ì ˆ ê°€ëŠ¥
scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)
print(np.mean(scores['train_score']), np.mean(scores['test_score']))
```
â¡ï¸ 0.8881086892152563 0.8720430147331015

ğŸ“Œ ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ íŠ¹ì§•: ê³¼ëŒ€ì í•©ì— ê°•í•˜ê³  ì¼ë°˜ì ìœ¼ë¡œ ë†’ì€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŒ. í•˜ì§€ë§Œ íŠ¸ë¦¬ë¥¼ ìˆœì„œëŒ€ë¡œ ì¶”ê°€í•˜ê¸°ì— í›ˆë ¨ ì†ë„ê°€ ëŠë¦¼. ì¦‰ n_jobs ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìŒ.

**â˜† íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…: ì…ë ¥ íŠ¹ì„±ì„ 256ê°œì˜ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ì´ ì¤‘ í•˜ë‚˜ë¥¼ ë–¼ì–´ ëˆ„ë½ëœ ê°’ì„ ìœ„í•´ ì‚¬ìš©í•¨.**

```python
#íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ì‹¤ìŠµ

from sklearn.experimental import enable_hist_gradient_boosting
from sklearn.ensemble import HistGradientBoostionClassifier
hgb = HistGradientBoostingClassfier(random_state=42)
scores = cross_validate(hgb, train_input, train_target, return_train_score=True)
print(np.mean(scores['train_score']), np.mean(scores['test_score']))
```
â¡ï¸ 0.9321723946453317 0.8801241948619236

âŠ• íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬: XGBoost, LightGBMì´ ëŒ€í‘œì .

```python
#XGBoostë¥¼ í™œìš©í•œ íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…

from xgboost import XGBClassifier
xgb = XGBClassifier(tree_method='hist', random_state=42) #tree_methodë¥¼ histë¡œ ì§€ì •í•˜ë©´ íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì„ ì‚¬ìš© ê°€ëŠ¥.
scores = cross_validate(xgb, train_input, train_target, return_train_score=True)

#LightGBMì„ í™œìš©í•œ íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…

from lightgbm import LGBMClassifier
lgb = LGBMClassifier(random_state=42)
scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)
```

### ì¶œì²˜ : í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹