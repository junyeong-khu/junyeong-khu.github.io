---
layout: post
title: "혼자 공부하는 머신러닝+딥러닝 : 1. 나의 첫 머신러닝"
date: 2024-07-29 03:01:45 +0900
categories: KHUDA
---
## <span style= 'background-color: #f1f8ff'>1-1: 인공지능과 머신러닝, 딥러닝
☆ **인공지능(artificial intelligence)**: 사람처럼 학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술
- **인공일반지능(강인공지능)**: 사람과 구분하기 어려운 지능을 가진 컴퓨터 시스템.
- **약인공지능**: 특정 분야에서 사람의 일을 도와주는 보조 역할만 가능한 시스템. 현실에서 우리가 마주하는 대부분의 인공지능.

☆ **머신러닝(machine learning)**: 자동으로 데이터에서 규칙을 학습하는 알고리즘을 연구하는 분야.
- **통계학과의 연관성**: 통계학에서 유래된 머신러닝 알고리즘이 다수.
- **경험 중심의 머신러닝의 발전**: 컴퓨터 과학 분야가 주도. 대표적인 머신러닝 라이브러리는 **사이킷런**으로 파이썬 API를 사용.
- **오픈소스 라이브러리의 발전과 머신러닝의 성장**: 과거 머신러닝이 폐쇄적인 라이브러리로 통용되어 있을 시절에는 소수의 사람들만 머신러닝을 배울 수 있었음. 사이킷런과 같은 오픈소스 라이브러리의 발전으로 많은 사람들이 머신러닝을 접할 수 있게 되었고, 머신러닝 분야는 폭발적으로 성장함.

☆ **딥러닝(deep learning)**: 인공 신경망을 기반으로 한 머신러닝 방법들의 통칭. 인공 신경망이라고 불리기도 함.
- **인공 신경망 발전의 원동력**: 풍부한 데이터, 컴퓨터 성능의 향상, 혁신적인 알고리즘 개발
- **대표적 라이브러리**: 텐서플로, 파이토치

## <span style= 'background-color: #f1f8ff'>1-2: 코랩과 주피터 노트북
☆ **코랩(Colab)**: 웹 브라우저에서 무료로 파이썬 프로그램을 테스트하고 저장할 수 있는 서비스.
- **코랩의 장점**: 구글 계정만 있다면 무료, 컴퓨터 성능에 관계엾이 프로그램을 실습해 볼 수 있음.
- **코랩의 텍스트 셀 툴**
![IMG_1120](https://github.com/user-attachments/assets/d77a2c81-0f0a-4749-b60d-9cd854a58767)
- **코랩의 텍스트 셀 마크다운**
![IMG_0151](https://github.com/user-attachments/assets/42846dd4-c856-489c-af24-60f00fc767cc)



☆ **노트북(Notebook)**: 코랩의 프로그램 작성 단위로 일반 프로그램 파일과 달리 대화식으로 프로그램을 만들 수 있음. 이는 코랩이 대화식 프로그래밍 환경인 **주피터**를 커스터마이징한 것이기 때문.

🚨 주의: 코랩 노트북은 한 번에 5개까지만 실행 가능.

## <span style= 'background-color: #f1f8ff'>1-3: 마켓과 머신러닝
☆ **k-최근접 이웃 알고리즘**: 어떤 데이터에 대한 답을 구할 때 주위의 다른 데이터를 보고 다수를 차지하는 것을 정답으로 사용하는 알고리즘.

☆ **k-최근접 이웃 알고리즘을 활용한 생선 분류 문제 해결 with 코랩**

➀ 데이터 준비 : 도미와 빙어의 길이, 무게 데이터를 리스트([]로 묶은 문자 혹은 숫자열)로 정의. 이때 두 리스트의 수들은 같은 자리에 있는 것끼리 대응. 이후 산점도로 표현.
```python
#데이터 준비에서 사용되는 명령어

import matplotlib.pyplot as plt #함수 사용을 위해 불러오는 명령어
plt.scatter(x, y) #산점도를 표시하는 명령어
plt.xlabel('') #x축에 표시할 변수를 표시하는 명령어
plt.show() #산점도를 출력하는 명령어
```
📌 Tip: 우리가 사용하는 맷플롯립에서 2개의 산점도를 한 그래프로 그릴 때는 scatter() 함수를 연달아 사용하면 됨. 이때 자동으로 색도 구분해서 나타남.

⊕ 이후 사용되는 명령어: plt.scatter(x, y, marker=' ')를 사용하면 특정 위치에 표시가 생김.

➁ 2차원 리스트 변환: 도미 데이터와 빙어 데이터를 하나의 리스트로 합친 후 2차원 리스트로 변환하는 과정. 사이킷런 패키지의 사용을 위해서는 2차원 리스트로 변환하는 과정이 필수.
```python
#2차원 리스트 변환에서 사용되는 명령어

fish_data = [[l,w] for l,w in zip(length, weight)]
#for는 반복문을 시작하는 명령어
#in은 어떤 컬렉션 안에 있는 항목을 하나씩 꺼내오게 하는 명령어
#zip()은 나열된 리스트에서 원소를 하나씩 꺼내주는 명령어
#위와 같이 []안에 명령어들이 있는 구문을 리스트 내포 구문이라 함
```
📌 2차원 리스트: 각 특성의 리스트를 세로 방향으로 늘어뜨린 리스트.

➂ 정답 데이터 준비: 머신러닝 알고리즘이 도미와 빙어를 구분하는 규칙을 찾게 하기 위해 우선 정답을 준비하는 과정.
```python
#정답 데이터 준비에서 사용되는 명령어

fish_target = [1] * 정수 + [0] * 정수 #정답 리스트를 만드는 과정. 찾으려는 대상을 1로 놓고 그 외의 것을 0으로 놓음
```
➃ k-최근접 이웃 알고리즘 구현 클래스 임포트 및 객체 생성: k-최근접 이웃 알고리즘을 구현한 클래스인 KNeighborsClassifier를 임포트하고 객체를 생성하는 과정.
```python
#k-최근접 이웃 알고리즘 구현 클래스 임포트 및 객체 생성에서 사용되는 명령어

from sklearn.neighbors import KNeighborsClassifier #패키지에서 특정 클래스만 임포트하는 명령어
kn = KNeighborsClassifier() #해당 함수의 객체를 만드는 명령어 
```
➄ 객체 훈련 및 평가: 해당 객체에 데이터와 정답 데이터를 전달하여 도미를 찾기 위한 기준을 학습시킨 후 정확도를 평가하는 과정.
```python
#객체 훈련 및 평가에서 사용되는 명령어

kn.fit(fish_data, fish_target) #주어진 데이터로 알고리즘을 훈련하는 명령어
kn.score(fish_data, fish_target) #주어진 데이터로 훈련한 알고리즘의 정확도를 평가하는 명령어. 0과 1사이의 값을 반환하며 1이 가장 정확함을 의미
kn.predict([[실수, 실수]]) #해당 알고리즘을 통해 예측하게 하는 명령어
```
☆ **k-최근접 이웃 알고리즘의 특징**: 가장 가까운 일부의 데이터를 참고하여 구분. 우리가 사용한 클래스의 기본값은 5. 보유한 데이터보다 참고하는 데이터가 많으면 정확도가 떨어짐. 데이터가 아주 많은 경우엔 사용하기 힘듦.

📌 마무리 문제
```python
#정확도가 1.0 아래로 내려가기 시작하는 이웃의 개수 찾기

kn = KNeighborsClassifier() #n_neighbors의 값만 바꾸면 되기 때문에 다시 만들 필요 없음 
kn.fit(fish_data, fish_target) #훈련은 데이터 저장이 끝이기에 데이터 값이 달라지지 않는 이상 매번 훈련시킬 필요 없음

for n in range(5, 50):
    #k-최근접 이웃 개수 설정
    kn.n_neighbors = n
    #점수 계산
    score = kn.score(fish_data, fish_target)
    #100% 정확도에 미치지 못하는 이웃 개수 출력
    if score < 1:
        print(n, score)
        break
```