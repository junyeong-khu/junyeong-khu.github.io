---
layout: post
title: "혼자 공부하는 머신러닝+딥러닝 : 2. 데이터 다루기"
date: 2024-07-29 03:01:45 +0900
categories: KHUDA
---
## <span style= 'background-color: #f1f8ff'>2-1: 훈련 세트와 테스트 세트
☆ **지도 학습과 비지도 학습**
- **지도 학습**: 입력(데이터)과 타깃(정답)으로 이뤄진 훈련 데이터가 필요한 학습.
- **비지도 학습**: 타깃 없이 입력 데이터만 사용하는 학습.
- 강화 학습: 알고리즘이 행동한 결과로 얻은 보상을 사용하는 학습. 해당 교재에서 다루지 않음.

☆ **훈련 세트와 테스트 세트**: 머신러닝 알고리즘의 성능을 제대로 평가하기 위해 필요한 요소들.
- **훈련 세트**: 머신러닝 알고리즘의 훈련에 사용되는 데이터.
- **테스트 세트**: 머신러닝 알고리즘의 평가에 사용되는 데이터.
- **훈련 세트와 테스트 세트를 준비하는 방법**: 다른 데이터를 준비하거나 이미 준비된 데이터 중에서 일부를 뗴어내어 활용. 후자를 주로 활용.
- **샘플링 편향**: 훈련 세트와 테스트 세트에는 샘플이 골고루 섞여 있어야 제대로 된 지도 학습 모델을 만들 수 있음. 이때 샘플이 골고루 섞여 있지 않은 경우를 **샘플링 편향**이라고 함.

☆ **넘파이를 활용한 생선 구분 머신러닝 프로그램**
1. 2차원 넘파이 배열 변환: 넘파이 배열로 변환하면 시작점이 왼쪽 위로 되며 행과 열이 맞는 형태로 출력됨.
```python
#2차원 넘파이 배열 변환에서 사용되는 명령어

import numpy as np #함수 사용을 위해 불러오는 명령어
input_arr = np.array(fish_data) #넘파이 배열로 fish_data를 변환시키는 명령어
```
2. 훈련 세트와 테스트 세트의 생성: 샘플링 편향 방지를 위해 무작위로 선택.
```python
#훈련 세트와 테스트 세트의 생성에서 사용되는 명령어

np.random.seed(정수) #랜덤 시드를 설정하는 명령어. 책과 동일한 결과를 재현하기 위해 사용
index = np.arrange(정수) #0에서 정수-1까지 1씩 증가하는 인덱스를 만드는 명령어
np.random.shuffle(index) #index의 배열을 무작위로 섞는 명령어

train_input = input_arr[index[:정수]] #0부터 정수-1까지의 input_arr에 저장된 배열을 train_input에 전달한 새로운 샘플을 만드는 명령어 

plt.scatter(train_input[:,0], train_input[:,1]) #산점도를 표현할 때 :,0은 1열을 x축으로, :,1은 2열을 Y축으로 표현하라는 의미
```
🚨 주의: 입력과 타깃이 함께 선택되어야 하기에 인덱스를 설정한 것.
📌 슬라이싱(:): 인덱스의 범위를 지정하는 연산자. 마지막 인덱스의 원소는 포함하지 않음.

3. 머신러닝 프로그램 훈련: 훈련 세트로 훈련 후 테스트 세트로 정확도를 테스트.
```python
#머신러닝 프로그램 훈련에서 사용되는 명령어

from sklearn.neighbors import KNeighborsClassifier #패키지에서 특정 클래스만 임포트하는 명령어
kn = KNeighborsClassifier() #해당 함수의 객체를 만드는 명령어 
kn = kn.fit(train_input, train_target) #주어진 데이터로 알고리즘을 훈련하는 명령어
kn.score(test_input, test_target) #주어진 데이터로 알고리즘의 정확도를 평가하는 명령어
```

## <span style= 'background-color: #f1f8ff'>2-2: 데이터 전처리
☆ **넘파이로 데이터 준비하기**
```python
import numpy as np #넘파이를 불러오며 np로 통칭함
fish_data = np.column_stack((fish_length, fish_weight)) #행과 열을 맞춘 하나의 리스트로 변환하는 명령어. 해당 과정을 fish_length와 fish_weight 리스트 내에 있는 요소 전부에 행함. 1-3에서 진행한 리스트 내포 구문과 유사
fish_target = np.concatenate((np.ones(정수), np.zeros(정수))) #정수 개의 1과 정수 개의 0으로 구성된 리스트를 하나의 리스트로 변환하는 명령어. column_stack과는 다르게 1줄로 나열함
```
🚨 주의: column_stack과 concatenate는 연결할 리스트나 배열을 튜플로 전달해야 하기에 소괄호를 사용.

☆ **사이킷런으로 훈련 세트와 테스트 세트 나누기**
```python
from sklearn.model_selection import train_test_split #패키지에서 특정 클래스만 임포트하는 명령어
train_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target, stratify=fish_target random_state=정수) #fish_data의 데이터를 train_input과 test_input에, fish_target의 데이터를 train_target과 test_target에 무작위로 나누어 줌. stratify를 활용해 샘플링 편향 방지. 인덱스의 지정이 필요 없음
```

☆ **이웃 샘플 찾기**
```python
distance, indexes = A.kneighbors([[실수, 실수]]) #괄호 안의 샘플과 가장 가까운 다섯 개의 샘플의 거리와 인덱스를 찾는 명령어
```
🚨 주의: 산점도로 출력할 경우 프로그램의 출력값이 이해되지 않을 수 있음. 이는 x축과 y축의 스케일 차이로 발생. xlim(())을 통해 두 축의 범위를 동일하게 설정할 경우 이해가 됨.

☆ **데이터 전처리**: k-최근접 이웃 알고리즘과 같은 거리 기반 알고리즘은 특성값을 일정한 기준으로 맞추어야 제대로 사용 가능. 이런 작업을 의미.

📌 표준점수: 데이터 전처리 과정에서 주로 활용하는 방법으로 평균을 뺀 후 표준편차로 나누어 구함.
```python
mean = np.mean(train_input, axis=0) #평균을 계산하는 명령어. 이때 axis를 0으로 설정해야 행을 따라 각 열의 통계 값을 계산함. 즉 평균이 두 개 나옴
std = np.std(train_iput, axis=0) #표준편차를 계산하는 명령어. 이때 axis를 0으로 설정해야 행을 따라 각 열의 통계 값을 계산함. 즉 표준편차가 두 개 나옴 
train_scaled = (train_input - mean) / std #표준점수를 계산하는 계산식. 넘파이는 알아서 열을 구분하여 평균을 빼고 표준편차를 나누어줌. 이를 브로드캐스팅이라 함
new = ([25,150] - mean) / std #테스트할 샘플의 표준점수를 계산하는 계산식. 넘파이는 알아서 열을 구분하여 평균을 빼고 표준편차를 나누어줌
kn.fit(train_scaled, train_target) #k-최근접 이웃 알고리즘을 다시 훈련시키는 과정
test_scaled = (test_input - mean) / std #테스트 세트의 스케일을 훈련 세트와 동일하게 변환하는 과정
kn.score(test_scaled, test_target)
```
🚨 주의: 테스트 세트는 훈련 세트의 평균과 표준편차를 이용하여 변환해야함. 그러지 않으면 두 세트의 스케일이 달라짐.

